{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is 1, ite is 937/937, loss is 0.07565319538116455\n",
      "epoch is 1, loss is 0.06827986985445023, accuracy is 0.9785\n",
      "epoch is 2, ite is 937/937, loss is 0.025464724749326706\n",
      "epoch is 2, loss is 0.06298859417438507, accuracy is 0.9787\n",
      "epoch is 3, ite is 937/937, loss is 0.008512557484209538\n",
      "epoch is 3, loss is 0.04482750594615936, accuracy is 0.9857\n",
      "epoch is 4, ite is 937/937, loss is 0.010595975443720818\n",
      "epoch is 4, loss is 0.05589539557695389, accuracy is 0.9829\n",
      "epoch is 5, ite is 937/937, loss is 0.001842342084273696\n",
      "epoch is 5, loss is 0.042814433574676514, accuracy is 0.9872\n",
      "epoch is 6, ite is 937/937, loss is 0.0834626704454422\n",
      "epoch is 6, loss is 0.06360015273094177, accuracy is 0.9816\n",
      "epoch is 7, ite is 937/937, loss is 0.001643711468204856\n",
      "epoch is 7, loss is 0.05787275359034538, accuracy is 0.9823\n",
      "epoch is 8, ite is 937/937, loss is 0.020839277654886246\n",
      "epoch is 8, loss is 0.051272936165332794, accuracy is 0.9858\n",
      "epoch is 9, ite is 937/937, loss is 0.0017867607530206442\n",
      "epoch is 9, loss is 0.05028066784143448, accuracy is 0.9861\n",
      "epoch is 10, ite is 937/937, loss is 0.04140092805027962\n",
      "epoch is 10, loss is 0.05705225095152855, accuracy is 0.9853\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# 1. Data\n",
    "train_data = dataset.MNIST(root=\"mnist\", \n",
    "                           train=True, \n",
    "                           transform=transforms.ToTensor(), \n",
    "                           download=True)\n",
    "\n",
    "test_data = dataset.MNIST(root=\"mnist\", \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor(), \n",
    "                           download=False)\n",
    "\n",
    "# batchsize\n",
    "train_loader = data_utils.DataLoader(dataset=train_data, \n",
    "                                     batch_size=64, \n",
    "                                     shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "test_loader = data_utils.DataLoader(dataset=test_data, \n",
    "                                     batch_size=64, \n",
    "                                     shuffle=True)\n",
    "\n",
    "\n",
    "# 2. Net\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=5, padding=2),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Linear(14 * 14 *32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "cnn = CNN()\n",
    "cnn = cnn.cuda()\n",
    "\n",
    "\n",
    "# 3. loss\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# 4. optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# 5. training\n",
    "\n",
    "for epoch in range(10):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = cnn(images)\n",
    "        loss = loss_func(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch is {}, ite is {}/{}, loss is {}\".format(epoch+1, \n",
    "                                                            i, \n",
    "                                                            len(train_data) // 64, \n",
    "                                                            loss.item()))\n",
    "\n",
    "\n",
    "# 6. evaluation\n",
    "    loss_test = 0\n",
    "    accuracy = 0\n",
    "    for i, (images, labels) in enumerate(test_loader):\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = cnn(images)\n",
    "\n",
    "        loss_test += loss_func(outputs, labels)\n",
    "        _, predicted = outputs.max(1)\n",
    "        accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = accuracy/len(test_data)\n",
    "    loss_test = loss_test / (len(test_data) // 64)\n",
    "\n",
    "    print(\"epoch is {}, loss is {}, accuracy is {}\".format(epoch+1,\n",
    "                                                           loss_test.item(),\n",
    "                                                           accuracy))\n",
    "\n",
    "# 7. save\n",
    "\n",
    "torch.save(cnn, \"minst_cnn.pkl\")\n",
    "\n",
    "# 8. load \n",
    "\n",
    "\n",
    "# 9. inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label 0\n",
      "pred 0\n",
      "label 7\n",
      "pred 9\n",
      "label 4\n",
      "pred 4\n",
      "label 7\n",
      "pred 7\n",
      "label 8\n",
      "pred 8\n",
      "label 3\n",
      "pred 3\n",
      "label 9\n",
      "pred 9\n",
      "label 0\n",
      "pred 0\n",
      "label 7\n",
      "pred 2\n",
      "label 8\n",
      "pred 8\n",
      "label 1\n",
      "pred 1\n",
      "label 7\n",
      "pred 9\n",
      "label 0\n",
      "pred 0\n",
      "label 1\n",
      "pred 1\n",
      "label 3\n",
      "pred 3\n",
      "label 6\n",
      "pred 6\n",
      "label 4\n",
      "pred 4\n",
      "label 3\n",
      "pred 3\n",
      "label 3\n",
      "pred 3\n",
      "label 9\n",
      "pred 9\n",
      "label 3\n",
      "pred 3\n",
      "label 6\n",
      "pred 6\n",
      "label 6\n",
      "pred 6\n",
      "label 4\n",
      "pred 4\n",
      "label 7\n",
      "pred 7\n",
      "label 5\n",
      "pred 5\n",
      "label 1\n",
      "pred 1\n",
      "label 3\n",
      "pred 3\n",
      "label 9\n",
      "pred 9\n",
      "label 8\n",
      "pred 8\n",
      "label 8\n",
      "pred 8\n",
      "label 1\n",
      "pred 1\n",
      "label 5\n",
      "pred 5\n",
      "label 0\n",
      "pred 0\n",
      "label 7\n",
      "pred 7\n",
      "label 7\n",
      "pred 7\n",
      "label 7\n",
      "pred 7\n",
      "label 7\n",
      "pred 7\n",
      "label 4\n",
      "pred 4\n",
      "label 6\n",
      "pred 6\n",
      "label 8\n",
      "pred 8\n",
      "label 6\n",
      "pred 6\n",
      "label 2\n",
      "pred 2\n",
      "label 0\n",
      "pred 0\n",
      "label 1\n",
      "pred 1\n",
      "label 9\n",
      "pred 9\n",
      "label 2\n",
      "pred 2\n",
      "label 1\n",
      "pred 1\n",
      "label 7\n",
      "pred 7\n",
      "label 2\n",
      "pred 2\n",
      "label 1\n",
      "pred 1\n",
      "label 7\n",
      "pred 7\n",
      "label 6\n",
      "pred 6\n",
      "label 6\n",
      "pred 6\n",
      "label 6\n",
      "pred 6\n",
      "label 9\n",
      "pred 9\n",
      "label 4\n",
      "pred 4\n",
      "label 8\n",
      "pred 8\n",
      "label 7\n",
      "pred 7\n",
      "label 3\n",
      "pred 3\n",
      "label 3\n",
      "pred 3\n",
      "label 8\n",
      "pred 8\n",
      "label 7\n",
      "pred 7\n",
      "label 0\n",
      "pred 0\n",
      "label 8\n",
      "pred 8\n",
      "label 4\n",
      "pred 4\n",
      "label 4\n",
      "pred 4\n",
      "label 2\n",
      "pred 2\n",
      "label 0\n",
      "pred 0\n",
      "label 8\n",
      "pred 8\n",
      "label 1\n",
      "pred 1\n",
      "label 6\n",
      "pred 6\n",
      "label 9\n",
      "pred 9\n",
      "label 7\n",
      "pred 7\n",
      "label 5\n",
      "pred 5\n",
      "label 0\n",
      "pred 0\n",
      "label 1\n",
      "pred 1\n",
      "label 2\n",
      "pred 2\n",
      "label 3\n",
      "pred 3\n",
      "label 9\n",
      "pred 9\n",
      "label 4\n",
      "pred 4\n",
      "label 3\n",
      "pred 3\n",
      "label 5\n",
      "pred 5\n",
      "label 3\n",
      "pred 3\n",
      "label 1\n",
      "pred 1\n",
      "label 3\n",
      "pred 3\n",
      "label 3\n",
      "pred 3\n",
      "label 5\n",
      "pred 5\n",
      "label 0\n",
      "pred 0\n",
      "label 9\n",
      "pred 9\n",
      "label 8\n",
      "pred 8\n",
      "label 2\n",
      "pred 2\n",
      "label 9\n",
      "pred 9\n",
      "label 8\n",
      "pred 8\n",
      "label 7\n",
      "pred 7\n",
      "label 6\n",
      "pred 6\n",
      "label 3\n",
      "pred 3\n",
      "label 3\n",
      "pred 3\n",
      "label 5\n",
      "pred 5\n",
      "label 8\n",
      "pred 8\n",
      "label 2\n",
      "pred 2\n",
      "label 2\n",
      "pred 2\n",
      "label 6\n",
      "pred 6\n",
      "label 7\n",
      "pred 7\n",
      "label 8\n",
      "pred 8\n",
      "label 9\n",
      "pred 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 73\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m\"\u001b[39m, im_pred)\n\u001b[0;32m     72\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, im_data)\n\u001b[1;32m---> 73\u001b[0m         \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     77\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(test_data)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(accuracy)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 载入model等\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data_utils\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 2. Net\n",
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=5, padding=2),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2)\n",
    "        )\n",
    "\n",
    "        self.fc = torch.nn.Linear(14 * 14 *32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size()[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "test_data = dataset.MNIST(root=\"mnist\", \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor(), \n",
    "                           download=False)\n",
    "\n",
    "# batchsize\n",
    "\n",
    "test_loader = data_utils.DataLoader(dataset=test_data, \n",
    "                                     batch_size=64, \n",
    "                                     shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "cnn = torch.load(\"minst_cnn.pkl\",weights_only=False)\n",
    "cnn = cnn.cuda()\n",
    "\n",
    "\n",
    "# 6. evaluation\n",
    "loss_test = 0\n",
    "accuracy = 0\n",
    "for i, (images, labels) in enumerate(test_loader):\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    outputs = cnn(images)\n",
    "    _, pred = outputs.max(1)\n",
    "    accuracy += (predicted == labels).sum().item()\n",
    "    \n",
    "    images = images.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    pred = pred.cpu().numpy()\n",
    "\n",
    "    # batchsize * 1 * 28 * 28\n",
    "\n",
    "    for idx in range(images.shape[0]):\n",
    "        im_data = images[idx]\n",
    "        im_label = labels[idx]\n",
    "        im_pred = pred[idx]\n",
    "        im_data = im_data.transpose(1, 2, 0)\n",
    "\n",
    "        print(\"label\", im_label)\n",
    "        print(\"pred\", im_pred)\n",
    "        cv2.imshow(\"imdata\", im_data)\n",
    "        cv2.waitKey(0) \n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy/len(test_data)\n",
    "print(accuracy)\n",
    "\n",
    "\n",
    "# 8. load \n",
    "\n",
    "\n",
    "# 9. inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
